{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I talked to Gaurav on July 11 after class and we thought of 2 architectures. In both cases, we will use transfer learning from something like BERT. In both cases, we want to get embeddings for:\n",
    "* the overview AND\n",
    "* some main features (like genres, production companies | director and actors may be harder to get an embedding for).\n",
    "Then, we will concat the two separate embeddings and use them for clustering. It would probably be better (and more natural) to train both halves together so the embeddings fit together.\n",
    "\n",
    "1. Multi-task learning.\n",
    "2. Have the genres or the production companies as \"style\". This will push the embeddings to form clusters.\n",
    "3. Train the overview separately (maybe for auto-encoder) and the features (maybe for classification) separately then concat them together.\n",
    "\n",
    "In all cases, the network must be trained to reach a goal, then the embeddings it came up with in the middle will be used for clsutering and interpolation.\n",
    "\n",
    "> Since I will be doing transfer learning, it is better to have a warmup_rate so I do not shock the weights. So, I start with a smaller learning rate then work up to the learning rate I want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fine tuning BERT for multi-label classfication](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=4wxY3x-ZZz8h)\n",
    "\n",
    "[Getting word and sentence embeddings from BERT](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEV_MODE = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\data_prep.py:20: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_movies = pd.read_csv(movies_metadata_path)\n",
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\data_prep.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  enough_votes['overview'] = enough_votes['overview'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "from data_prep import load_movies_full_df\n",
    "\n",
    "MIN_VOTES_PER_MOVIE = 50\n",
    "NEUTRAL_RATING = 2.5\n",
    "MIN_POSITIVE_VOTES_PER_USER = 20\n",
    "DESIRED_COLUMNS = ['id', 'cast', 'title', 'crew',\n",
    "                   'genres', 'overview', 'production_companies']\n",
    "\n",
    "df = load_movies_full_df(\n",
    "        movies_metadata_path='data/IMDB_Ratings/movies_metadata.csv',\n",
    "        credits_path='data/IMDB_Ratings/credits.csv',\n",
    "        n_votes=MIN_VOTES_PER_MOVIE,\n",
    "        desired_columns=DESIRED_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cast</th>\n",
       "      <th>title</th>\n",
       "      <th>crew</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>[{'cast_id': 25, 'character': 'Lt. Vincent Han...</td>\n",
       "      <td>Heat</td>\n",
       "      <td>[{'credit_id': '52fe4292c3a36847f802916d', 'de...</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>[{'name': 'Regency Enterprises', 'id': 508}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               cast  \\\n",
       "0    862  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1   8844  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2  15602  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3  11862  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "4    949  [{'cast_id': 25, 'character': 'Lt. Vincent Han...   \n",
       "\n",
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3  Father of the Bride Part II   \n",
       "4                         Heat   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...   \n",
       "3  [{'credit_id': '52fe44959251416c75039ed7', 'de...   \n",
       "4  [{'credit_id': '52fe4292c3a36847f802916d', 'de...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "4  [{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Just when George Banks has recovered from his ...   \n",
       "4  Obsessive master thief, Neil McCauley leads a ...   \n",
       "\n",
       "                                production_companies  \n",
       "0     [{'name': 'Pixar Animation Studios', 'id': 3}]  \n",
       "1  [{'name': 'TriStar Pictures', 'id': 559}, {'na...  \n",
       "2  [{'name': 'Warner Bros.', 'id': 6194}, {'name'...  \n",
       "3  [{'name': 'Sandollar Productions', 'id': 5842}...  \n",
       "4  [{'name': 'Regency Enterprises', 'id': 508}, {...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV_MODE:\n",
    "    df = df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for classification\n",
    "\n",
    "We will use the genres of the movies (and maybe the production companies later) as the labels of the movie. This will result in this becoming a multi-label problem, since most movies fall under more than one genre.\n",
    "\n",
    "> A question to answer is whether we should only keep it as the top 3 genres, or have all genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing stringified objects into Python readable objects ...\n",
      "Extracting top 3 genres ...\n"
     ]
    }
   ],
   "source": [
    "from features import get_top_n_per_feature, parse_into_python_objects\n",
    "\n",
    "# the csv files have stringified objects to represnt the cast, the crew, the genres and the prodiction companies\n",
    "# we have to parse them into python objects\n",
    "df = parse_into_python_objects(df, ['cast', 'crew', 'genres', 'production_companies'])\n",
    "\n",
    "# let's extract the top 3 genres and the top 2 production companies of a movie into lists (instead of objects)\n",
    "df = get_top_n_per_feature(df, [('genres', 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80       [Action, Crime, Fantasy]\n",
       "81               [Drama, Romance]\n",
       "82               [Action, Comedy]\n",
       "83      [Fantasy, Comedy, Family]\n",
       "84        [Mystery, Crime, Drama]\n",
       "85     [Action, Adventure, Drama]\n",
       "86      [Action, Thriller, Drama]\n",
       "87                  [Documentary]\n",
       "88      [Thriller, Action, Crime]\n",
       "89     [Drama, Mystery, Thriller]\n",
       "90             [Action, Thriller]\n",
       "91        [Action, Comedy, Crime]\n",
       "92     [Action, Adventure, Drama]\n",
       "93                    [Adventure]\n",
       "94      [Action, Crime, Thriller]\n",
       "95     [Adventure, Action, Drama]\n",
       "96              [Science Fiction]\n",
       "97                 [Drama, Crime]\n",
       "98                [Drama, Comedy]\n",
       "99    [Mystery, Horror, Thriller]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn genres into one-hot-encoded columns\n",
    "\n",
    "To classify the movies over genres, we have to turn them into one-hot encoded columns, where each column represents a genre, and it's value is 1 if the movie falls under this genre and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the genres\n",
    "# note: it is better for memory to use a sparse matrix, but it is not compatible with the tokenizer\n",
    "# solution taken from: https://stackoverflow.com/questions/45312377/how-to-one-hot-encode-from-a-pandas-column-containing-a-list\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "\n",
    "df = df.join(\n",
    "        pd.DataFrame(\n",
    "            mlb_genres.fit_transform(df.pop('genres')),\n",
    "            columns=mlb_genres.classes_,\n",
    "            index=df.index\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Family',\n",
       " 'Fantasy',\n",
       " 'History',\n",
       " 'Horror',\n",
       " 'Music',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Science Fiction',\n",
       " 'Thriller',\n",
       " 'War']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_names = mlb_genres.classes_.tolist()\n",
    "genre_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Production Companies\n",
    "Now that we added the genres. We can also try to add the production companies. We can add the top 2 production companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genres'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genres'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\final_explore.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=0'>1</a>\u001b[0m mlb_prod_companies \u001b[39m=\u001b[39m MultiLabelBinarizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=3'>4</a>\u001b[0m         pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=4'>5</a>\u001b[0m             mlb_prod_companies\u001b[39m.\u001b[39mfit_transform(df\u001b[39m.\u001b[39;49mpop(\u001b[39m'\u001b[39;49m\u001b[39mgenres\u001b[39;49m\u001b[39m'\u001b[39;49m)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=5'>6</a>\u001b[0m             columns\u001b[39m=\u001b[39mmlb_prod_companies\u001b[39m.\u001b[39mclasses_,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=6'>7</a>\u001b[0m             index\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mindex\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=7'>8</a>\u001b[0m         )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\frame.py:5270\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m   5230\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5231\u001b[0m \u001b[39m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5232\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5268\u001b[0m \u001b[39m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5270\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpop(item\u001b[39m=\u001b[39;49mitem)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\generic.py:865\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m Any:\n\u001b[1;32m--> 865\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[item]\n\u001b[0;32m    866\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[0;32m    868\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genres'"
     ]
    }
   ],
   "source": [
    "mlb_prod_companies = MultiLabelBinarizer()\n",
    "\n",
    "df = df.join(\n",
    "        pd.DataFrame(\n",
    "            mlb_prod_companies.fit_transform(df.pop('production_companies')),\n",
    "            columns=mlb_prod_companies.classes_,\n",
    "            index=df.index\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_company_names = mlb_prod_companies.classes_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label indices\n",
    "To ease our training, we will map our labels from strings to integers. Later on, we might want to map them back to their string format for interpretability. \n",
    "\n",
    "We will keep this flexible to accomodate for the genres only, the production companies only, or both.\n",
    "\n",
    "> Idea: can I do multi-task learning where I use the same input to train two-classifiers: one for the genres and one for the production companies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = genre_names # + prod_company_names\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "We will split the dataset into training-testing (80%-20%) to help with the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "\n",
    "# create a mask to split data into training and testing\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "# TODO should I drop all the columns that I do not need (i.e., cast, crew, maybe title)\n",
    "dataset = DatasetDict(\n",
    "    train = Dataset.from_pandas(df[msk]),\n",
    "    test = Dataset.from_pandas(df[~msk])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the max length of tokens\n",
    "\n",
    "The tokenizer will turn the words in a sentence into IDs. Since BERT is a neural network, it takes a fixed size input (i.e., fixed number of tokens) everytime. Nonetheless, not all ovewrviews have the same length. \n",
    "\n",
    "To overcome this problem, we give ourt tokenizer a `max_length` that all inputs should have. \n",
    "- If the overview has less words than `max_length`, we add `[PAD]` tokens to it till it reaches this `max_length`. \n",
    "- If the overview has more words than `max_length`, we turncate it to only have as many words as `max_length`.\n",
    "\n",
    "To find a good `max_length` we will run simple statistics on the overview column of our dataset and we will use the 95th percentile of token length as our tokens' `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      51.180000\n",
       "std       23.965202\n",
       "min        7.000000\n",
       "25%       31.500000\n",
       "50%       52.000000\n",
       "75%       67.250000\n",
       "max      123.000000\n",
       "Name: overview, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df['overview'].str.split().str.len()\n",
    "count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_max_length = count.quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding/tokenizing the overview\n",
    "\n",
    "The tokenizer will turn the words in a sentence into IDs, which correspond to the IDs that the original BERT used to represent words when it was training. This is crucial for the transfer-learning to work, to ensure consistency between the representations of the words that we will use.\n",
    "\n",
    "Moreover, we will need the labels of each class to be used as the output of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"overview\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(\n",
    "    text, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    max_length=int(tokens_max_length), \n",
    "    # return_tensors='pt'\n",
    "  ) # .to(device)\n",
    "  \n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  encoding[\"id\"] = examples[\"id\"]\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?ba/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\final_explore.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=0'>1</a>\u001b[0m encoded_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=1'>2</a>\u001b[0m     preprocess_data, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=2'>3</a>\u001b[0m     batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m# default batch size is 1,000\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=3'>4</a>\u001b[0m     \u001b[39m# the returned values will have a new shape, \u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=4'>5</a>\u001b[0m     \u001b[39m# so we must drop the old columns lest we have shape mismatch problems\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=5'>6</a>\u001b[0m     remove_columns\u001b[39m=\u001b[39;49mdataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mcolumn_names \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\dataset_dict.py:770\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 770\u001b[0m     {\n\u001b[0;32m    771\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[0;32m    772\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[0;32m    773\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[0;32m    774\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[0;32m    775\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[0;32m    776\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[0;32m    777\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m    778\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    779\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[0;32m    780\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    781\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    782\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    783\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    784\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[0;32m    785\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[0;32m    786\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[0;32m    787\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[0;32m    788\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    790\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    791\u001b[0m     }\n\u001b[0;32m    792\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\dataset_dict.py:771\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    770\u001b[0m     {\n\u001b[1;32m--> 771\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    772\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m    773\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m    774\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m    775\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m    776\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m    777\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    778\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m    779\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m    780\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m    781\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m    782\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[0;32m    783\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m    784\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    785\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m    786\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m    787\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m    788\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    790\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    791\u001b[0m     }\n\u001b[0;32m    792\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\arrow_dataset.py:2376\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2373\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[0;32m   2375\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 2376\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[0;32m   2377\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m   2378\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m   2379\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m   2380\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m   2381\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m   2382\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2383\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m   2384\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m   2385\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m   2386\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m   2387\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[0;32m   2388\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m   2389\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m   2390\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m   2391\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m   2392\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[0;32m   2393\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[0;32m   2394\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m   2395\u001b[0m     )\n\u001b[0;32m   2396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2398\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\arrow_dataset.py:551\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    550\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 551\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    552\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    553\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    554\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\arrow_dataset.py:518\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    512\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    513\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    514\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    515\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    516\u001b[0m }\n\u001b[0;32m    517\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    519\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    520\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\fingerprint.py:458\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m             kwargs[fingerprint_name] \u001b[39m=\u001b[39m update_fingerprint(\n\u001b[0;32m    453\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[0;32m    454\u001b[0m             )\n\u001b[0;32m    456\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 458\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\arrow_dataset.py:2764\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[0;32m   2760\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2761\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(input_dataset\u001b[39m.\u001b[39mnum_rows)))\n\u001b[0;32m   2762\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2764\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[0;32m   2765\u001b[0m         batch,\n\u001b[0;32m   2766\u001b[0m         indices,\n\u001b[0;32m   2767\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(input_dataset\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2768\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   2769\u001b[0m     )\n\u001b[0;32m   2770\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   2771\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   2772\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2773\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\arrow_dataset.py:2644\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   2642\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   2643\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 2644\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[0;32m   2645\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2646\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[0;32m   2647\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\datasets\\arrow_dataset.py:2336\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[1;34m(item, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[0;32m   2333\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[0;32m   2334\u001b[0m )\n\u001b[0;32m   2335\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[1;32m-> 2336\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2337\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\final_explore.ipynb Cell 25\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=7'>8</a>\u001b[0m text \u001b[39m=\u001b[39m examples[\u001b[39m\"\u001b[39m\u001b[39moverview\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=8'>9</a>\u001b[0m \u001b[39m# encode them\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=9'>10</a>\u001b[0m encoding \u001b[39m=\u001b[39m tokenizer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=10'>11</a>\u001b[0m   text, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=11'>12</a>\u001b[0m   padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=12'>13</a>\u001b[0m   truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=13'>14</a>\u001b[0m   max_length\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(tokens_max_length), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=14'>15</a>\u001b[0m   \u001b[39m# return_tensors='pt'\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=15'>16</a>\u001b[0m )\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=17'>18</a>\u001b[0m \u001b[39m# add labels\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000027?line=18'>19</a>\u001b[0m labels_batch \u001b[39m=\u001b[39m {k: examples[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m examples\u001b[39m.\u001b[39mkeys() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m labels}\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\transformers\\utils\\import_utils.py:829\u001b[0m, in \u001b[0;36mtorch_required.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 829\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    830\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMethod `\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` requires PyTorch.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:746\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[39m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[39m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[39m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m _is_torch_device(device) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 746\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    747\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(device)\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:746\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[39m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[39m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[39m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m _is_torch_device(device) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 746\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39mdevice) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    747\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(device)\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data, \n",
    "    batched=True, # default batch size is 1,000\n",
    "    # the returned values will have a new shape, \n",
    "    # so we must drop the old columns lest we have shape mismatch problems\n",
    "    remove_columns=dataset['train'].column_names \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] led by woody, andy's toys live happily in his room until andy's birthday brings buzz lightyear onto the scene. afraid of losing his place in andy's heart, woody plots against buzz. but when circumstances separate buzz and woody from their owner, the duo eventually learns to put aside their differences. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation', 'Comedy', 'Family']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the format of our data to PyTorch tensors. \n",
    "# This will turn the training, validation and test sets into standard PyTorch datasets\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "We will use a pre-trained BERT model and do transfer-learning to classify the overviews into genres. This means that we have a multi-label classification problem, and we will have to modify the BERT pretrained model that we are given as it only supports binary classificatoin by default.\n",
    "\n",
    "It is important to note that we primairly do this classification to encode some movie specific data into the embeddings of words/sentence of the overview. The final goal is to take these embeddings and use their domain to run nearest-neighbor or interpolation to find movie recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\User/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Action\",\n",
      "    \"1\": \"Adventure\",\n",
      "    \"2\": \"Animation\",\n",
      "    \"3\": \"Comedy\",\n",
      "    \"4\": \"Crime\",\n",
      "    \"5\": \"Documentary\",\n",
      "    \"6\": \"Drama\",\n",
      "    \"7\": \"Family\",\n",
      "    \"8\": \"Fantasy\",\n",
      "    \"9\": \"History\",\n",
      "    \"10\": \"Horror\",\n",
      "    \"11\": \"Music\",\n",
      "    \"12\": \"Mystery\",\n",
      "    \"13\": \"Romance\",\n",
      "    \"14\": \"Science Fiction\",\n",
      "    \"15\": \"Thriller\",\n",
      "    \"16\": \"War\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Action\": 0,\n",
      "    \"Adventure\": 1,\n",
      "    \"Animation\": 2,\n",
      "    \"Comedy\": 3,\n",
      "    \"Crime\": 4,\n",
      "    \"Documentary\": 5,\n",
      "    \"Drama\": 6,\n",
      "    \"Family\": 7,\n",
      "    \"Fantasy\": 8,\n",
      "    \"History\": 9,\n",
      "    \"Horror\": 10,\n",
      "    \"Music\": 11,\n",
      "    \"Mystery\": 12,\n",
      "    \"Romance\": 13,\n",
      "    \"Science Fiction\": 14,\n",
      "    \"Thriller\": 15,\n",
      "    \"War\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\User/.cache\\huggingface\\transformers\\a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# TODO we should tell the model that we will want to extract the embeddings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,\n",
    "                                                           output_hidden_states=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things:\n",
    "\n",
    "- `TrainingArguments`, which specify training hyperparameters. All options can be found in the docs. Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "- a `Trainer` object (docs can be found here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "metric_name = \"f1\" # TODO should I use accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2419,  2011, 13703,  1010,  5557,  1005,  1055, 10899,  2444,\n",
       "        11361,  1999,  2010,  2282,  2127,  5557,  1005,  1055,  5798,  7545,\n",
       "        12610,  2422, 29100,  3031,  1996,  3496,  1012,  4452,  1997,  3974,\n",
       "         2010,  2173,  1999,  5557,  1005,  1055,  2540,  1010, 13703, 14811,\n",
       "         2114, 12610,  1012,  2021,  2043,  6214,  3584, 12610,  1998, 13703,\n",
       "         2013,  2037,  3954,  1010,  1996,  6829,  2776, 10229,  2000,  2404,\n",
       "         4998,  2037,  5966,  1012,   102,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7168, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.4976,  0.7592, -0.1099, -0.1505,  0.3372, -0.2077, -0.2145, -0.0220,\n",
       "         -0.2930, -0.0139, -0.3660,  0.0062,  0.4493, -0.4902,  0.1032, -0.1988,\n",
       "         -0.3099]], grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [ 0.8878,  0.2431,  0.2230,  ...,  0.3238,  0.7185, -0.1581],\n",
       "         [-0.0733,  0.2378,  0.6102,  ...,  0.3972, -0.2210,  0.4207],\n",
       "         ...,\n",
       "         [ 0.0159, -0.4712,  0.2090,  ..., -0.2394, -0.3774,  0.1976],\n",
       "         [ 0.1598, -0.3782,  0.1954,  ..., -0.1481, -0.5739,  0.1019],\n",
       "         [-0.0436, -0.5786,  0.5365,  ..., -0.2000, -0.4886, -0.0453]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0451, -0.0058, -0.2221,  ...,  0.2417, -0.1131,  0.0159],\n",
       "         [ 0.7613, -0.0737, -0.2307,  ...,  0.2185,  0.9615, -0.3208],\n",
       "         [-0.2301, -0.3402,  0.6632,  ...,  0.3455, -0.0892,  0.7178],\n",
       "         ...,\n",
       "         [ 0.1314, -0.3147,  0.2033,  ...,  0.1085, -0.1477,  0.1345],\n",
       "         [ 0.2990, -0.2221,  0.2215,  ...,  0.1985, -0.3056,  0.0717],\n",
       "         [ 0.1695, -0.3594,  0.3505,  ...,  0.1156, -0.1796, -0.1550]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0903, -0.1447, -0.4021,  ...,  0.2275, -0.0369, -0.0241],\n",
       "         [ 0.6395,  0.0811, -0.5646,  ...,  0.2747,  1.1800, -0.9469],\n",
       "         [-0.3147, -0.6880,  1.0082,  ...,  0.4220, -0.1208,  0.5000],\n",
       "         ...,\n",
       "         [ 0.1046, -0.6552,  0.5743,  ...,  0.1273, -0.0417,  0.1560],\n",
       "         [ 0.3726, -0.4553,  0.6224,  ...,  0.3636, -0.2782, -0.0225],\n",
       "         [ 0.1349, -0.6988,  0.9070,  ...,  0.3014, -0.1539, -0.2850]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0055, -0.2614, -0.2217,  ...,  0.2442,  0.0883,  0.0821],\n",
       "         [ 0.3940,  0.0119, -0.8238,  ...,  0.4068,  0.2363, -0.6171],\n",
       "         [-0.1562, -0.3282,  0.9554,  ...,  0.1736, -0.0623,  0.2257],\n",
       "         ...,\n",
       "         [ 0.2639, -0.7957,  0.5043,  ..., -0.1124,  0.3149,  0.0748],\n",
       "         [ 0.4944, -0.7137,  0.6174,  ..., -0.0438,  0.1201, -0.0752],\n",
       "         [ 0.2677, -0.6633,  0.9053,  ...,  0.0370,  0.0324, -0.5139]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1203, -0.7718, -0.7243,  ...,  0.0630,  0.2809,  0.3134],\n",
       "         [ 0.2938,  0.3044, -1.1818,  ...,  0.4554,  0.4342, -0.8369],\n",
       "         [-0.4906, -0.6178,  0.4405,  ...,  0.5776,  0.4227,  0.2951],\n",
       "         ...,\n",
       "         [ 0.3144, -0.9128,  0.6661,  ..., -0.1625,  0.3056,  0.2178],\n",
       "         [ 0.4616, -0.7540,  0.8778,  ..., -0.1301,  0.1040,  0.0541],\n",
       "         [ 0.4088, -0.8129,  0.9033,  ..., -0.1177, -0.2085, -0.5706]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-8.8026e-02, -7.9822e-01, -4.7154e-01,  ...,  2.2653e-01,\n",
       "           1.9575e-01,  3.0621e-01],\n",
       "         [ 7.7370e-01,  9.2434e-01, -1.4899e+00,  ...,  6.4649e-01,\n",
       "           3.8978e-01, -5.3947e-01],\n",
       "         [-1.5852e-01, -6.1460e-01,  5.7254e-01,  ...,  3.0183e-01,\n",
       "           5.3537e-01,  1.8873e-01],\n",
       "         ...,\n",
       "         [ 5.2935e-01, -3.7435e-01,  5.7401e-01,  ..., -9.3120e-02,\n",
       "           5.7285e-01,  1.5118e-01],\n",
       "         [ 6.2837e-01, -2.9594e-01,  5.8446e-01,  ..., -1.1031e-03,\n",
       "           3.4622e-01,  8.0232e-02],\n",
       "         [ 6.1303e-01, -7.5531e-02,  5.6455e-01,  ..., -3.8997e-02,\n",
       "          -2.5500e-02, -5.7840e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1177, -0.9244, -0.1132,  ...,  0.1354,  0.2958,  0.1340],\n",
       "         [ 0.5755,  0.6168, -0.7342,  ...,  0.8921, -0.2996, -0.7291],\n",
       "         [-0.4018, -0.5353,  0.6548,  ...,  0.3916,  0.0797,  0.6254],\n",
       "         ...,\n",
       "         [-0.0257, -0.4252,  0.6178,  ..., -0.0711,  0.4271, -0.3194],\n",
       "         [ 0.1211, -0.3800,  0.5474,  ..., -0.0450,  0.3281, -0.5061],\n",
       "         [ 0.1177, -0.0019,  0.4189,  ...,  0.0129,  0.0095, -1.3642]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3313, -0.9132,  0.1844,  ...,  0.1981,  0.1525,  0.0258],\n",
       "         [ 0.0934,  1.1133, -0.4044,  ...,  0.9527, -0.2510, -0.7033],\n",
       "         [-0.8288, -0.1112,  0.9084,  ...,  0.5791,  0.0486,  1.1199],\n",
       "         ...,\n",
       "         [ 0.2956, -0.4134,  0.5370,  ..., -0.0180,  0.4747, -0.5117],\n",
       "         [ 0.4252, -0.2823,  0.4668,  ...,  0.0920,  0.3137, -0.6329],\n",
       "         [ 0.5897,  0.3747,  0.1556,  ...,  0.0561, -0.0541, -1.4725]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0907, -0.6030, -0.2352,  ..., -0.0506,  0.1066, -0.2056],\n",
       "         [ 0.1832,  0.9839, -0.7453,  ...,  0.5107, -0.6145, -0.6646],\n",
       "         [-0.8512, -0.1002,  0.7071,  ...,  0.7217,  0.1635,  1.0486],\n",
       "         ...,\n",
       "         [ 0.2130, -0.5159,  0.5905,  ...,  0.0740,  0.4983, -0.7705],\n",
       "         [ 0.2261, -0.4653,  0.5420,  ...,  0.1140,  0.3728, -0.9420],\n",
       "         [ 0.3144,  0.1588,  0.3210,  ..., -0.0112,  0.0032, -1.7772]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-1.3135e-01, -3.6844e-01, -1.1282e-01,  ...,  2.6912e-01,\n",
       "          -1.4798e-02, -1.4409e-01],\n",
       "         [ 1.9598e-01,  1.2018e+00, -6.5149e-01,  ..., -1.1438e-01,\n",
       "          -7.9439e-01, -7.2972e-01],\n",
       "         [-7.4868e-01, -2.3806e-01,  3.1410e-01,  ...,  1.1174e+00,\n",
       "          -3.6894e-02,  6.2360e-01],\n",
       "         ...,\n",
       "         [-1.0464e-03, -6.7715e-01,  7.2971e-01,  ..., -3.7395e-01,\n",
       "           4.8987e-01, -8.7698e-01],\n",
       "         [-3.6278e-03, -6.8498e-01,  5.7989e-01,  ..., -2.4799e-01,\n",
       "           3.5416e-01, -1.1173e+00],\n",
       "         [ 2.4517e-01, -1.4544e-02,  2.8128e-01,  ..., -2.0457e-01,\n",
       "           5.6022e-02, -2.0376e+00]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4157, -0.8546,  0.0346,  ...,  0.3248,  0.0473, -0.0507],\n",
       "         [ 0.1320,  0.9890, -0.3887,  ..., -0.2034, -0.8548, -0.5207],\n",
       "         [-1.2112, -0.1849,  0.6178,  ...,  0.7288, -0.0212,  0.6789],\n",
       "         ...,\n",
       "         [-0.0457, -0.6048,  0.8199,  ..., -0.3963,  0.3359, -1.2263],\n",
       "         [-0.1626, -0.8104,  0.6158,  ..., -0.2379,  0.3082, -1.4545],\n",
       "         [ 0.0534, -0.3813,  0.2249,  ..., -0.2024,  0.1484, -2.2577]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4056, -0.6200,  0.0392,  ...,  0.4487,  0.2409, -0.3016],\n",
       "         [ 0.2205,  0.8266, -0.2966,  ...,  0.1668, -0.9946, -0.1918],\n",
       "         [-1.0564, -0.1607,  0.5581,  ...,  1.0477, -0.3809,  0.8083],\n",
       "         ...,\n",
       "         [ 0.0116, -0.4215,  1.0773,  ..., -0.4728,  0.4364, -1.5179],\n",
       "         [-0.0885, -0.6331,  0.8216,  ..., -0.3097,  0.4153, -1.7196],\n",
       "         [ 0.2829, -0.2573,  0.2899,  ..., -0.3135,  0.2443, -2.4439]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.7658, -0.1278, -0.1038,  ...,  0.2158,  0.9719, -0.7026],\n",
       "         [-0.1559,  0.3352, -0.1241,  ...,  0.1694, -0.0734, -0.1517],\n",
       "         [-0.9333,  0.0583,  0.1408,  ...,  0.6041, -0.1133,  0.5260],\n",
       "         ...,\n",
       "         [ 0.1553, -0.3078,  0.8813,  ..., -0.5851,  0.0665, -1.3685],\n",
       "         [ 0.1255, -0.3859,  0.8182,  ..., -0.5494,  0.0988, -1.5057],\n",
       "         [ 0.2751, -0.1919,  0.5808,  ..., -0.6224,  0.2293, -1.9840]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(\n",
    "    input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), \n",
    "    labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    # TODO are these datasets on GPU or CPU?\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 82\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 55\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                     \n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "  0%|          | 0/5 [25:21<?, ?it/s]          \n",
      "\u001b[A\n",
      "\u001b[ASaving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-11\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-11\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5841608643531799, 'eval_f1': 0.1927710843373494, 'eval_roc_auc': 0.5334100322135297, 'eval_accuracy': 0.0, 'eval_runtime': 4.2447, 'eval_samples_per_second': 4.241, 'eval_steps_per_second': 0.707, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-11\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-11\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-11\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                     \n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "  0%|          | 0/5 [27:21<?, ?it/s]          \n",
      "\u001b[A\n",
      "\u001b[ASaving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-22\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-22\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5170652270317078, 'eval_f1': 0.3448275862068965, 'eval_roc_auc': 0.6087436723423838, 'eval_accuracy': 0.05555555555555555, 'eval_runtime': 6.8896, 'eval_samples_per_second': 2.613, 'eval_steps_per_second': 0.435, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-22\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-22\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-22\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                     \n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "  0%|          | 0/5 [29:15<?, ?it/s]          \n",
      "\u001b[A\n",
      "\u001b[ASaving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-33\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-33\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4737803041934967, 'eval_f1': 0.29629629629629634, 'eval_roc_auc': 0.5881270133456051, 'eval_accuracy': 0.1111111111111111, 'eval_runtime': 7.0915, 'eval_samples_per_second': 2.538, 'eval_steps_per_second': 0.423, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-33\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-33\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-33\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                     \n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "  0%|          | 0/5 [31:15<?, ?it/s]          \n",
      "\u001b[A\n",
      "\u001b[ASaving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-44\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-44\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4563661217689514, 'eval_f1': 0.1702127659574468, 'eval_roc_auc': 0.5450069028992177, 'eval_accuracy': 0.1111111111111111, 'eval_runtime': 7.3994, 'eval_samples_per_second': 2.433, 'eval_steps_per_second': 0.405, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-44\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-44\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-44\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                     \n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "  0%|          | 0/5 [32:55<?, ?it/s]          \n",
      "\u001b[A\n",
      "\u001b[ASaving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-55\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-55\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4487520754337311, 'eval_f1': 0.20833333333333334, 'eval_roc_auc': 0.5572020248504372, 'eval_accuracy': 0.1111111111111111, 'eval_runtime': 6.4136, 'eval_samples_per_second': 2.807, 'eval_steps_per_second': 0.468, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-55\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-55\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-55\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from bert-finetuned-sem_eval-english\\checkpoint-22 (score: 0.3448275862068965).\n",
      "                                     \n",
      "100%|| 55/55 [08:43<00:00,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 523.5059, 'train_samples_per_second': 0.783, 'train_steps_per_second': 0.105, 'train_loss': 0.5314006458629261, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=55, training_loss=0.5314006458629261, metrics={'train_runtime': 523.5059, 'train_samples_per_second': 0.783, 'train_steps_per_second': 0.105, 'train_loss': 0.5314006458629261, 'epoch': 5.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is done training (i.e. fine-tuning), we should save it to have an easy way to re-use in the future if we so desire.\n",
    "We will use the `model.save_pretrained(<PATH_TO_STORAGE_DIRECTORY>)` method that hugging face provides.\n",
    "\n",
    "In the future, if we want to retreive this dine-tuned model, all we have to do is call `AutoModelForSequenceClassification.from_pretrained(<PATH_TO_STORAGE_DIRECTORY>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL_PICKELING_DIRECTORY = './bert_model'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(PATH_TO_MODEL_PICKELING_DIRECTORY):\n",
    "    os.makedirs(PATH_TO_MODEL_PICKELING_DIRECTORY)\n",
    "else:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings from BERT\n",
    "\n",
    "Now that the models is trained, we need to extract the embeddings from the last layer.\n",
    "\n",
    "1. Add special characters (`[CLS]`:start and `[SEP]`:end) to each sentence.\n",
    "2. Tokenize each sentence according to BERT's characters.\n",
    "3. Put the label with the sentence.\n",
    "> Note: The first 3 steps are already done in our `encoded_dataset`\n",
    "4. Set the `model` to the evaluation mode\n",
    "5. Stop keeping track of the gradient\n",
    "6. Pass the tokens tensor and the labels tensor to the `model` and save the output into a variable. This simply passes the inputs through one full forward pass of the model.\n",
    "7. Extract the embeddings from this output variable, from the second last layer. \\*\\*\n",
    "8. Combine the embeddings of the words to get an embedding of the setence. One sentence will have the second last layer of size `(int(tokens_max_length), 768)` and a batch of size `batch_size` will result in size `(batch_size, int(tokens_max_length), 768)`. `768` is the number of hidden features. To combine, we average the features over the words, to get a final vector of size `(batch_size, 768)`\n",
    "\n",
    "#### \\*\\* Deciding on which layer to use\n",
    "\n",
    "> Taken from [the FAQ](https://github.com/jina-ai/clip-as-service#speech_balloon-faq) of CLIP-as-service.\n",
    "\n",
    "1. The embeddings start out in the first layer as having no contextual information (i.e., the meaning of a word does not take into account what the word means in this specific sentence).\n",
    "2. As the embeddings move deeper into the network, they pick up more and more contextual information with each layer.\n",
    "3. As you approach the final layer, however, you start picking up information that is specific to BERTs pre-training tasks (the Masked Language Model (MLM) and Next Sentence Prediction (NSP)).\n",
    "    * What we want is embeddings that encode the word meaning well\n",
    "    * BERT is motivated to do this, but it is also motivated to encode anything else that would help it determine what a missing word is (MLM), or whether the second sentence came after the first (NSP).\n",
    "4. The second-to-last layer is what CLIP-as-service settled on as a reasonable sweet-spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model to evaluation mode so we do not update any weights\n",
    "model.eval()\n",
    "\n",
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from the last layer. \n",
    "with torch.no_grad():\n",
    "\n",
    "    # this evaluates the model (a.k.a. finds the outputs) for only one sentence\n",
    "    # outputs = model(\n",
    "    #     input_ids=encoded_dataset['train']['input_ids'][10].unsqueeze(0),\n",
    "    #     labels=encoded_dataset['train'][10]['labels'].unsqueeze(0))\n",
    "\n",
    "    # this evaluates the model (a.k.a. finds the outputs) for the first 10 sentences\n",
    "    # TODO we will do the same for batches (maybe size 64)\n",
    "    outputs = model(\n",
    "        input_ids=encoded_dataset['train']['input_ids'][:10],\n",
    "        labels=encoded_dataset['train'][:10]['labels'])\n",
    "\n",
    "    # get the features in the last layer\n",
    "    # TODO is it better to get the features in the second last layer [-2] than the last layer [-1]\n",
    "    last_layer = outputs.hidden_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the representation of a sentence, combine all the words embeddings (by averaging them) to become a single sentence embedding\n",
    "# in other words, we want to get rid of the middle dimension (the <SENTENCE_LENGTH> dimension), which is at index 1 of the shape\n",
    "# the shape is (batch_size, sentence_length, num_features_in_hidden_state)\n",
    "sentence_embedding = last_layer.mean(1)\n",
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a vector that represents each sentence, we need to write it to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import csv\n",
    "\n",
    "SENTENCE_EMBEDDING_FILE = 'sentence_embeddings.csv'\n",
    "\n",
    "with open(SENTENCE_EMBEDDING_FILE, 'a', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for sentence in sentence_embedding:\n",
    "        writer.writerow(sentence.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best to zip this csv as it will have a large size and might be difficult to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2019,  2035,  1011,  2732,  3459,  4204,  2023,  8680,  2298,\n",
       "          2012,  2137,  2343,  2957,  1049,  1012, 11296,  1010,  1037,  2158,\n",
       "          4755,  1996,  6580,  1997,  1996,  2088,  2006,  2010,  4065,  2096,\n",
       "         17773,  1996,  2969,  1011, 15615,  7670,  2306,  1012, 13912,  2010,\n",
       "         11587,  2879,  9021,  1999,  2662,  2000,  1996, 16880,  2300,  5867,\n",
       "          9446,  2008,  2052,  2203,  2010,  8798,  1012,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "894b74110dc0cb78bc9a7fb989438ed7fabe7ad8d7a782ec4a035d78b61e245b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
