{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I talked to Gaurav on July 11 after class and we thought of 2 architectures. In both cases, we will use transfer learning from something like BERT. In both cases, we want to get embeddings for:\n",
    "* the overview AND\n",
    "* some main features (like genres, production companies | director and actors may be harder to get an embedding for).\n",
    "Then, we will concat the two separate embeddings and use them for clustering. It would probably be better (and more natural) to train both halves together so the embeddings fit together.\n",
    "\n",
    "1. Multi-task learning.\n",
    "2. Have the genres or the production companies as \"style\". This will push the embeddings to form clusters.\n",
    "3. Train the overview separately (maybe for auto-encoder) and the features (maybe for classification) separately then concat them together.\n",
    "\n",
    "In all cases, the network must be trained to reach a goal, then the embeddings it came up with in the middle will be used for clsutering and interpolation.\n",
    "\n",
    "> Since I will be doing transfer learning, it is better to have a warmup_rate so I do not shock the weights. So, I start with a smaller learning rate then work up to the learning rate I want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fine tuning BERT for multi-label classfication](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=4wxY3x-ZZz8h)\n",
    "\n",
    "[Getting word and sentence embeddings from BERT](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEV_MODE = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\data_prep.py:20: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_movies = pd.read_csv(movies_metadata_path)\n",
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\data_prep.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  enough_votes['overview'] = enough_votes['overview'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "from data_prep import load_movies_full_df\n",
    "\n",
    "MIN_VOTES_PER_MOVIE = 50\n",
    "NEUTRAL_RATING = 2.5\n",
    "MIN_POSITIVE_VOTES_PER_USER = 20\n",
    "DESIRED_COLUMNS = ['id', 'cast', 'title', 'crew',\n",
    "                   'genres', 'overview', 'production_companies']\n",
    "\n",
    "df = load_movies_full_df(\n",
    "        movies_metadata_path='data/IMDB_Ratings/movies_metadata.csv',\n",
    "        credits_path='data/IMDB_Ratings/credits.csv',\n",
    "        n_votes=MIN_VOTES_PER_MOVIE,\n",
    "        desired_columns=DESIRED_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cast</th>\n",
       "      <th>title</th>\n",
       "      <th>crew</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>[{'cast_id': 25, 'character': 'Lt. Vincent Han...</td>\n",
       "      <td>Heat</td>\n",
       "      <td>[{'credit_id': '52fe4292c3a36847f802916d', 'de...</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>[{'name': 'Regency Enterprises', 'id': 508}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               cast  \\\n",
       "0    862  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1   8844  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2  15602  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3  11862  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "4    949  [{'cast_id': 25, 'character': 'Lt. Vincent Han...   \n",
       "\n",
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3  Father of the Bride Part II   \n",
       "4                         Heat   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...   \n",
       "3  [{'credit_id': '52fe44959251416c75039ed7', 'de...   \n",
       "4  [{'credit_id': '52fe4292c3a36847f802916d', 'de...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "4  [{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Just when George Banks has recovered from his ...   \n",
       "4  Obsessive master thief, Neil McCauley leads a ...   \n",
       "\n",
       "                                production_companies  \n",
       "0     [{'name': 'Pixar Animation Studios', 'id': 3}]  \n",
       "1  [{'name': 'TriStar Pictures', 'id': 559}, {'na...  \n",
       "2  [{'name': 'Warner Bros.', 'id': 6194}, {'name'...  \n",
       "3  [{'name': 'Sandollar Productions', 'id': 5842}...  \n",
       "4  [{'name': 'Regency Enterprises', 'id': 508}, {...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV_MODE:\n",
    "    df = df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for classification\n",
    "\n",
    "We will use the genres of the movies (and maybe the production companies later) as the labels of the movie. This will result in this becoming a multi-label problem, since most movies fall under more than one genre.\n",
    "\n",
    "> A question to answer is whether we should only keep it as the top 3 genres, or have all genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import get_distil_data\n",
    "\n",
    "df = get_distil_data('distil_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing stringified objects into Python readable objects ...\n",
      "Extracting top 3 genres ...\n"
     ]
    }
   ],
   "source": [
    "from features import get_top_n_per_feature, parse_into_python_objects\n",
    "\n",
    "# the csv files have stringified objects to represnt the cast, the crew, the genres and the prodiction companies\n",
    "# we have to parse them into python objects\n",
    "df = parse_into_python_objects(df, ['cast', 'crew', 'genres', 'production_companies'])\n",
    "\n",
    "# let's extract the top 3 genres and the top 2 production companies of a movie into lists (instead of objects)\n",
    "df = get_top_n_per_feature(df, [('genres', 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['id', 'overview', 'genres']].to_csv('distil_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80       [Action, Crime, Fantasy]\n",
       "81               [Drama, Romance]\n",
       "82               [Action, Comedy]\n",
       "83      [Fantasy, Comedy, Family]\n",
       "84        [Mystery, Crime, Drama]\n",
       "85     [Action, Adventure, Drama]\n",
       "86      [Action, Thriller, Drama]\n",
       "87                  [Documentary]\n",
       "88      [Thriller, Action, Crime]\n",
       "89     [Drama, Mystery, Thriller]\n",
       "90             [Action, Thriller]\n",
       "91        [Action, Comedy, Crime]\n",
       "92     [Action, Adventure, Drama]\n",
       "93                    [Adventure]\n",
       "94      [Action, Crime, Thriller]\n",
       "95     [Adventure, Action, Drama]\n",
       "96              [Science Fiction]\n",
       "97                 [Drama, Crime]\n",
       "98                [Drama, Comedy]\n",
       "99    [Mystery, Horror, Thriller]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn genres into one-hot-encoded columns\n",
    "\n",
    "To classify the movies over genres, we have to turn them into one-hot encoded columns, where each column represents a genre, and it's value is 1 if the movie falls under this genre and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the genres\n",
    "# note: it is better for memory to use a sparse matrix, but it is not compatible with the tokenizer\n",
    "# solution taken from: https://stackoverflow.com/questions/45312377/how-to-one-hot-encode-from-a-pandas-column-containing-a-list\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "\n",
    "df = df.join(\n",
    "        pd.DataFrame(\n",
    "            mlb_genres.fit_transform(df.pop('genres')),\n",
    "            columns=mlb_genres.classes_,\n",
    "            index=df.index\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Family',\n",
       " 'Fantasy',\n",
       " 'History',\n",
       " 'Horror',\n",
       " 'Music',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Science Fiction',\n",
       " 'Thriller',\n",
       " 'War']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_names = mlb_genres.classes_.tolist()\n",
    "genre_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Production Companies\n",
    "Now that we added the genres. We can also try to add the production companies. We can add the top 2 production companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genres'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genres'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641_cymourad_project\\final_explore.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=0'>1</a>\u001b[0m mlb_prod_companies \u001b[39m=\u001b[39m MultiLabelBinarizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=3'>4</a>\u001b[0m         pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=4'>5</a>\u001b[0m             mlb_prod_companies\u001b[39m.\u001b[39mfit_transform(df\u001b[39m.\u001b[39;49mpop(\u001b[39m'\u001b[39;49m\u001b[39mgenres\u001b[39;49m\u001b[39m'\u001b[39;49m)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=5'>6</a>\u001b[0m             columns\u001b[39m=\u001b[39mmlb_prod_companies\u001b[39m.\u001b[39mclasses_,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=6'>7</a>\u001b[0m             index\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mindex\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=7'>8</a>\u001b[0m         )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/MSCI-2023/1C-Spring22/MSCI-641/Project/msci641_cymourad_project/final_explore.ipynb#ch0000011?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\frame.py:5270\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m   5230\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5231\u001b[0m \u001b[39m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5232\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5268\u001b[0m \u001b[39m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5270\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpop(item\u001b[39m=\u001b[39;49mitem)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\generic.py:865\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m Any:\n\u001b[1;32m--> 865\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[item]\n\u001b[0;32m    866\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[0;32m    868\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'genres'"
     ]
    }
   ],
   "source": [
    "mlb_prod_companies = MultiLabelBinarizer()\n",
    "\n",
    "df = df.join(\n",
    "        pd.DataFrame(\n",
    "            mlb_prod_companies.fit_transform(df.pop('production_companies')),\n",
    "            columns=mlb_prod_companies.classes_,\n",
    "            index=df.index\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_company_names = mlb_prod_companies.classes_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label indices\n",
    "To ease our training, we will map our labels from strings to integers. Later on, we might want to map them back to their string format for interpretability. \n",
    "\n",
    "We will keep this flexible to accomodate for the genres only, the production companies only, or both.\n",
    "\n",
    "> Idea: can I do multi-task learning where I use the same input to train two-classifiers: one for the genres and one for the production companies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = genre_names # + prod_company_names\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "We will split the dataset into training-testing (80%-20%) to help with the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "\n",
    "# create a mask to split data into training and testing\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "# TODO should I drop all the columns that I do not need (i.e., cast, crew, maybe title)\n",
    "dataset = DatasetDict(\n",
    "    train = Dataset.from_pandas(df[msk]),\n",
    "    test = Dataset.from_pandas(df[~msk])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the max length of tokens\n",
    "\n",
    "The tokenizer will turn the words in a sentence into IDs. Since BERT is a neural network, it takes a fixed size input (i.e., fixed number of tokens) everytime. Nonetheless, not all ovewrviews have the same length. \n",
    "\n",
    "To overcome this problem, we give ourt tokenizer a `max_length` that all inputs should have. \n",
    "- If the overview has less words than `max_length`, we add `[PAD]` tokens to it till it reaches this `max_length`. \n",
    "- If the overview has more words than `max_length`, we turncate it to only have as many words as `max_length`.\n",
    "\n",
    "To find a good `max_length` we will run simple statistics on the overview column of our dataset and we will use the 95th percentile of token length as our tokens' `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      51.180000\n",
       "std       23.965202\n",
       "min        7.000000\n",
       "25%       31.500000\n",
       "50%       52.000000\n",
       "75%       67.250000\n",
       "max      123.000000\n",
       "Name: overview, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = df['overview'].str.split().str.len()\n",
    "count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_max_length = count.quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding/tokenizing the overview\n",
    "\n",
    "The tokenizer will turn the words in a sentence into IDs, which correspond to the IDs that the original BERT used to represent words when it was training. This is crucial for the transfer-learning to work, to ensure consistency between the representations of the words that we will use.\n",
    "\n",
    "Moreover, we will need the labels of each class to be used as the output of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"overview\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(\n",
    "    text, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    max_length=int(tokens_max_length), \n",
    "    # return_tensors='pt'\n",
    "  ) # .to(device)\n",
    "  \n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  encoding[\"id\"] = examples[\"id\"]\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.53ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.71ba/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data, \n",
    "    batched=True, # default batch size is 1,000\n",
    "    # the returned values will have a new shape, \n",
    "    # so we must drop the old columns lest we have shape mismatch problems\n",
    "    remove_columns=dataset['train'].column_names \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] when siblings judy and peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite alan - - an adult who's been trapped inside the game for 26 years - - into their living room. alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures. [SEP] [PAD] [PAD]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventure', 'Family', 'Fantasy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the format of our data to PyTorch tensors. \n",
    "# This will turn the training, validation and test sets into standard PyTorch datasets\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "We will use a pre-trained BERT model and do transfer-learning to classify the overviews into genres. This means that we have a multi-label classification problem, and we will have to modify the BERT pretrained model that we are given as it only supports binary classificatoin by default.\n",
    "\n",
    "It is important to note that we primairly do this classification to encode some movie specific data into the embeddings of words/sentence of the overview. The final goal is to take these embeddings and use their domain to run nearest-neighbor or interpolation to find movie recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# TODO we should tell the model that we will want to extract the embeddings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,\n",
    "                                                           output_hidden_states=True)\n",
    "\n",
    "# no need to send the model explicitly to the GPU, the trainer will do that for me\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things:\n",
    "\n",
    "- `TrainingArguments`, which specify training hyperparameters. All options can be found in the docs. Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "- a `Trainer` object (docs can be found here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "metric_name = \"f1\" # TODO should I use accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2043,  9504, 12120,  1998,  2848,  7523,  2019, 22454,  2604,\n",
       "         2208,  2008,  7480,  1996,  2341,  2000,  1037,  8687,  2088,  1010,\n",
       "         2027,  4895,  9148, 13027,  2135, 13260,  5070,  1011,  1011,  2019,\n",
       "         4639,  2040,  1005,  1055,  2042,  7567,  2503,  1996,  2208,  2005,\n",
       "         2656,  2086,  1011,  1011,  2046,  2037,  2542,  2282,  1012,  5070,\n",
       "         1005,  1055,  2069,  3246,  2005,  4071,  2003,  2000,  3926,  1996,\n",
       "         2208,  1010,  2029, 16481, 19188,  2004,  2035,  2093,  2424,  3209,\n",
       "         2770,  2013,  5016, 24091, 17119, 27465,  1010,  4763, 17059,  1998,\n",
       "         2060, 17082,  7329,  1012,   102,     0,     0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7722, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.8062,  0.0043,  0.5874,  0.3624,  0.0475,  0.1799,  0.5663,  0.5486,\n",
       "         -0.2649, -0.5155, -0.3317, -0.3034,  0.5412, -0.2086, -0.0707,  0.0891,\n",
       "          0.5054]], grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [-0.4807,  0.8188, -0.4227,  ..., -0.1415,  1.1064,  0.5430],\n",
       "         [ 0.1751, -0.3431, -1.0606,  ..., -0.1269,  0.5795, -0.2664],\n",
       "         ...,\n",
       "         [-0.4976,  0.1075,  0.3954,  ..., -0.6796,  0.0103, -0.0790],\n",
       "         [ 0.1598, -0.3782,  0.1954,  ..., -0.1481, -0.5739,  0.1019],\n",
       "         [-0.0436, -0.5786,  0.5365,  ..., -0.2000, -0.4886, -0.0453]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0608, -0.0230, -0.2425,  ...,  0.2075, -0.0869, -0.0231],\n",
       "         [-1.3177,  0.7007, -0.4374,  ..., -0.2224,  0.9212,  0.7522],\n",
       "         [ 0.0589, -0.4386, -0.5371,  ..., -0.0360,  0.6879, -0.1282],\n",
       "         ...,\n",
       "         [-0.5081, -0.1510,  0.3278,  ..., -0.3907, -0.0603, -0.0810],\n",
       "         [-0.0812, -0.5278,  0.4394,  ...,  0.5106, -0.4778, -0.1122],\n",
       "         [-0.1043, -0.5731,  0.5376,  ...,  0.3777, -0.2905, -0.2761]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1099, -0.2334, -0.4907,  ...,  0.2240,  0.0671, -0.1205],\n",
       "         [-1.5930,  0.2787, -0.5921,  ..., -0.2732,  0.5439,  0.3658],\n",
       "         [-0.0955, -0.4982, -0.5845,  ..., -0.0862,  1.1973, -0.1020],\n",
       "         ...,\n",
       "         [-0.2539, -0.1869,  0.0480,  ..., -0.1834,  0.1854, -0.4712],\n",
       "         [-0.0932, -0.5454,  0.2474,  ...,  0.9536, -0.7711, -0.1357],\n",
       "         [-0.2870, -0.7706,  0.5167,  ...,  0.6935, -0.5586, -0.2026]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0437, -0.3328, -0.2887,  ...,  0.2767,  0.2397,  0.0076],\n",
       "         [-1.5046,  0.5002, -0.1711,  ..., -0.6071,  0.2279,  0.4730],\n",
       "         [-0.2982, -0.0265, -0.8376,  ...,  0.0221,  0.9432,  0.0910],\n",
       "         ...,\n",
       "         [-0.0823, -0.0917,  0.0770,  ...,  0.0209,  0.0546, -0.0753],\n",
       "         [-0.1201, -0.2646,  0.4848,  ...,  0.8692, -0.5700, -0.0187],\n",
       "         [-0.5448, -0.5476,  0.5636,  ...,  0.7515, -0.3426, -0.1594]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.0131e-01, -6.8997e-01, -7.9059e-01,  ...,  2.1369e-01,\n",
       "           2.7584e-01,  3.1303e-01],\n",
       "         [-1.2165e+00,  3.7466e-01, -2.8883e-01,  ..., -3.0761e-01,\n",
       "          -7.6653e-02,  6.2166e-01],\n",
       "         [-2.6320e-01, -2.5477e-01, -1.0155e+00,  ..., -2.4260e-01,\n",
       "           8.9699e-01,  4.2372e-01],\n",
       "         ...,\n",
       "         [-2.6621e-02, -4.8131e-02, -7.7110e-05,  ..., -5.1902e-03,\n",
       "           4.0308e-02, -3.3491e-02],\n",
       "         [ 8.2470e-02, -4.8659e-01,  6.9676e-01,  ...,  7.0405e-01,\n",
       "          -2.6124e-01,  3.1087e-02],\n",
       "         [-3.7120e-01, -8.5444e-01,  7.3685e-01,  ...,  4.9364e-01,\n",
       "          -1.2943e-01, -7.0176e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0342, -0.8676, -0.5570,  ...,  0.0255,  0.2609,  0.3597],\n",
       "         [-1.3510,  0.5879, -0.5341,  ..., -0.2741, -0.2785,  0.5190],\n",
       "         [-0.2761, -0.2685, -1.4089,  ..., -0.1777,  0.8931, -0.0734],\n",
       "         ...,\n",
       "         [-0.0166, -0.0436,  0.0324,  ..., -0.0043,  0.0041, -0.0465],\n",
       "         [ 0.2655, -0.2482,  0.4838,  ..., -0.0039,  0.0321,  0.0907],\n",
       "         [-0.0931, -0.5422,  0.3815,  ...,  0.0853, -0.0612, -0.1155]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0835, -1.1489, -0.2446,  ..., -0.2116,  0.5140,  0.2649],\n",
       "         [-1.5802,  0.6439, -0.5402,  ..., -0.5780, -1.1004,  0.9707],\n",
       "         [-0.8190, -0.6632, -1.9655,  ..., -0.4133,  0.0278, -0.7367],\n",
       "         ...,\n",
       "         [ 0.0305, -0.0464, -0.0052,  ..., -0.0228, -0.0096, -0.0420],\n",
       "         [ 0.1563, -0.3631,  0.3845,  ..., -0.4320, -0.4345,  0.1566],\n",
       "         [-0.1236, -0.6532,  0.1936,  ..., -0.2423, -0.6114, -0.1302]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0049, -1.1672, -0.6042,  ..., -0.4004,  0.2965,  0.0444],\n",
       "         [-2.1233,  0.8960, -0.5382,  ..., -0.6136, -0.9224,  0.7971],\n",
       "         [-1.2719, -0.5163, -1.7467,  ..., -0.5486,  0.1528, -0.4167],\n",
       "         ...,\n",
       "         [ 0.0240,  0.0191, -0.0245,  ..., -0.0269,  0.0141, -0.0380],\n",
       "         [-0.2304,  0.0201,  0.6269,  ...,  0.0427, -0.3491,  0.4885],\n",
       "         [-0.2743, -0.2784,  0.4570,  ...,  0.2813, -0.5438,  0.2924]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1399, -0.8144, -0.3881,  ..., -0.4177,  0.1116,  0.0634],\n",
       "         [-2.3586,  0.9160, -0.3986,  ..., -0.5029, -0.6322,  0.2527],\n",
       "         [-1.2937, -0.3416, -1.0890,  ..., -0.5116,  0.3388, -0.3667],\n",
       "         ...,\n",
       "         [ 0.0287,  0.0558,  0.0298,  ..., -0.0316, -0.0344, -0.0665],\n",
       "         [-0.2861,  0.3200,  0.5261,  ...,  0.2595, -0.2992, -0.1424],\n",
       "         [-0.1371,  0.3154,  0.5119,  ...,  0.2423, -0.6101, -0.1913]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0201, -0.6289, -0.4604,  ...,  0.0215,  0.4352,  0.0480],\n",
       "         [-2.2528,  0.8463, -0.3411,  ..., -0.8828, -0.1535,  0.2123],\n",
       "         [-1.3129, -0.2479, -0.9453,  ..., -0.4825,  0.7755, -0.4931],\n",
       "         ...,\n",
       "         [-0.0264, -0.0181,  0.0227,  ..., -0.0209,  0.0082, -0.0619],\n",
       "         [-0.1782,  0.1486,  0.4073,  ...,  0.3731, -0.1696, -0.2153],\n",
       "         [-0.1417,  0.3025,  0.5004,  ...,  0.2876, -0.3887, -0.1283]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-5.1749e-01, -9.8105e-01, -9.4680e-04,  ...,  4.4893e-01,\n",
       "           2.6513e-01,  3.8908e-01],\n",
       "         [-2.8261e+00,  8.5720e-01, -2.1432e-03,  ..., -4.9297e-01,\n",
       "          -5.3422e-01,  1.3532e-01],\n",
       "         [-1.2150e+00,  7.6002e-02, -5.3159e-01,  ..., -8.3191e-01,\n",
       "           7.1974e-01, -4.8106e-01],\n",
       "         ...,\n",
       "         [-6.6601e-01, -5.0049e-01,  1.4523e-01,  ...,  5.1389e-01,\n",
       "          -9.7559e-02,  8.7384e-02],\n",
       "         [-4.2138e-01,  2.9041e-01,  6.4667e-01,  ...,  3.1531e-01,\n",
       "           3.4549e-01,  6.3801e-02],\n",
       "         [-3.8848e-01,  4.0055e-01,  6.5743e-01,  ...,  3.6199e-01,\n",
       "          -9.5164e-02,  1.0107e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.5532, -0.4359,  0.2298,  ...,  0.5813,  0.0941,  0.7836],\n",
       "         [-2.3202,  1.0714,  0.1721,  ..., -0.3988, -0.7295,  0.0694],\n",
       "         [-0.8751,  0.4055, -0.5855,  ..., -0.8747,  0.7744, -0.0719],\n",
       "         ...,\n",
       "         [-0.4699, -0.3788,  0.3813,  ...,  0.6882, -0.2583,  0.1324],\n",
       "         [-0.0507,  0.4393,  0.8314,  ...,  0.2184,  0.2310,  0.2378],\n",
       "         [ 0.1374,  0.4917,  0.8417,  ...,  0.1887, -0.2571,  0.3337]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.5234, -0.1487,  0.1232,  ...,  0.4309,  0.4951,  0.8514],\n",
       "         [-1.3639,  0.5005,  0.0902,  ...,  0.1474, -0.0114,  0.0680],\n",
       "         [-0.5345,  0.2645, -0.7161,  ..., -0.7164,  0.5558, -0.1155],\n",
       "         ...,\n",
       "         [-0.5561, -0.1856,  0.2212,  ...,  0.7374, -0.1366, -0.1844],\n",
       "         [-0.0513,  0.1043,  0.3369,  ...,  0.1482,  0.1071, -0.0041],\n",
       "         [ 0.0404,  0.1272,  0.2991,  ...,  0.0839, -0.0168,  0.0403]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(\n",
    "    input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), \n",
    "    labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    # TODO are these datasets on GPU or CPU?\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id. If id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\User\\Desktop\\MSCI-2023\\1C-Spring22\\MSCI-641\\Project\\msci641-env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n",
      " 20%|██        | 3/15 [00:48<03:03, 15.28s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id. If id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 19\n",
      "  Batch size = 32\n",
      "                                              \n",
      " 20%|██        | 3/15 [00:52<03:03, 15.28s/it]Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-3\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-3\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6802330613136292, 'eval_f1': 0.18072289156626506, 'eval_roc_auc': 0.48156146179402, 'eval_accuracy': 0.0, 'eval_runtime': 4.2324, 'eval_samples_per_second': 4.489, 'eval_steps_per_second': 0.236, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-3\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-3\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-3\\special_tokens_map.json\n",
      " 40%|████      | 6/15 [01:49<02:38, 17.58s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id. If id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 19\n",
      "  Batch size = 32\n",
      "                                              \n",
      " 40%|████      | 6/15 [01:54<02:38, 17.58s/it]Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-6\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-6\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6383912563323975, 'eval_f1': 0.17460317460317462, 'eval_roc_auc': 0.4993355481727575, 'eval_accuracy': 0.0, 'eval_runtime': 4.7501, 'eval_samples_per_second': 4.0, 'eval_steps_per_second': 0.211, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-6\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-6\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-6\\special_tokens_map.json\n",
      " 60%|██████    | 9/15 [03:04<02:03, 20.61s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id. If id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 19\n",
      "  Batch size = 32\n",
      "                                              \n",
      " 60%|██████    | 9/15 [03:08<02:03, 20.61s/it]Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-9\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-9\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6200209856033325, 'eval_f1': 0.17857142857142858, 'eval_roc_auc': 0.510921926910299, 'eval_accuracy': 0.0, 'eval_runtime': 4.1768, 'eval_samples_per_second': 4.549, 'eval_steps_per_second': 0.239, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-9\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-9\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-9\\special_tokens_map.json\n",
      " 80%|████████  | 12/15 [04:00<00:54, 18.23s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id. If id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 19\n",
      "  Batch size = 32\n",
      "                                               \n",
      " 80%|████████  | 12/15 [04:04<00:54, 18.23s/it]Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-12\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-12\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6076399087905884, 'eval_f1': 0.18556701030927836, 'eval_roc_auc': 0.5242940199335547, 'eval_accuracy': 0.0, 'eval_runtime': 4.1619, 'eval_samples_per_second': 4.565, 'eval_steps_per_second': 0.24, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-12\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-12\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-12\\special_tokens_map.json\n",
      "100%|██████████| 15/15 [04:50<00:00, 16.00s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id. If id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 19\n",
      "  Batch size = 32\n",
      "                                               \n",
      "100%|██████████| 15/15 [04:53<00:00, 16.00s/it]Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-15\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-15\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6023359894752502, 'eval_f1': 0.17391304347826086, 'eval_roc_auc': 0.5198089700996676, 'eval_accuracy': 0.0, 'eval_runtime': 3.2832, 'eval_samples_per_second': 5.787, 'eval_steps_per_second': 0.305, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-15\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-15\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-15\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from bert-finetuned-sem_eval-english\\checkpoint-12 (score: 0.18556701030927836).\n",
      "100%|██████████| 15/15 [04:57<00:00, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 297.9549, 'train_samples_per_second': 1.359, 'train_steps_per_second': 0.05, 'train_loss': 0.6434092203776042, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=0.6434092203776042, metrics={'train_runtime': 297.9549, 'train_samples_per_second': 1.359, 'train_steps_per_second': 0.05, 'train_loss': 0.6434092203776042, 'epoch': 5.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is done training (i.e. fine-tuning), we should save it to have an easy way to re-use in the future if we so desire.\n",
    "We will use the `model.save_pretrained(<PATH_TO_STORAGE_DIRECTORY>)` method that hugging face provides.\n",
    "\n",
    "In the future, if we want to retreive this dine-tuned model, all we have to do is call `AutoModelForSequenceClassification.from_pretrained(<PATH_TO_STORAGE_DIRECTORY>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL_PICKELING_DIRECTORY = './bert_model'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(PATH_TO_MODEL_PICKELING_DIRECTORY):\n",
    "    os.makedirs(PATH_TO_MODEL_PICKELING_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings from BERT\n",
    "\n",
    "Now that the models is trained, we need to extract the embeddings from the last layer.\n",
    "\n",
    "1. Add special characters (`[CLS]`:start and `[SEP]`:end) to each sentence.\n",
    "2. Tokenize each sentence according to BERT's characters.\n",
    "3. Put the label with the sentence.\n",
    "> Note: The first 3 steps are already done in our `encoded_dataset`\n",
    "4. Set the `model` to the evaluation mode\n",
    "5. Stop keeping track of the gradient\n",
    "6. Pass the tokens tensor and the labels tensor to the `model` and save the output into a variable. This simply passes the inputs through one full forward pass of the model.\n",
    "7. Extract the embeddings from this output variable, from the second last layer. \\*\\*\n",
    "8. Combine the embeddings of the words to get an embedding of the setence. One sentence will have the second last layer of size `(int(tokens_max_length), 768)` and a batch of size `batch_size` will result in size `(batch_size, int(tokens_max_length), 768)`. `768` is the number of hidden features. To combine, we average the features over the words, to get a final vector of size `(batch_size, 768)`\n",
    "\n",
    "#### \\*\\* Deciding on which layer to use\n",
    "\n",
    "> Taken from [the FAQ](https://github.com/jina-ai/clip-as-service#speech_balloon-faq) of CLIP-as-service.\n",
    "\n",
    "1. The embeddings start out in the first layer as having no contextual information (i.e., the meaning of a word does not take into account what the word means in this specific sentence).\n",
    "2. As the embeddings move deeper into the network, they pick up more and more contextual information with each layer.\n",
    "3. As you approach the final layer, however, you start picking up information that is specific to BERT’s pre-training tasks (the “Masked Language Model” (MLM) and “Next Sentence Prediction” (NSP)).\n",
    "    * What we want is embeddings that encode the word meaning well…\n",
    "    * BERT is motivated to do this, but it is also motivated to encode anything else that would help it determine what a missing word is (MLM), or whether the second sentence came after the first (NSP).\n",
    "4. The second-to-last layer is what CLIP-as-service settled on as a reasonable sweet-spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model to evaluation mode so we do not update any weights\n",
    "model.eval()\n",
    "\n",
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from the last layer. \n",
    "with torch.no_grad():\n",
    "\n",
    "    # this evaluates the model (a.k.a. finds the outputs) for only one sentence\n",
    "    # outputs = model(\n",
    "    #     input_ids=encoded_dataset['train']['input_ids'][10].unsqueeze(0),\n",
    "    #     labels=encoded_dataset['train'][10]['labels'].unsqueeze(0))\n",
    "\n",
    "    data = encoded_dataset['train'][:10]\n",
    "\n",
    "    # this evaluates the model (a.k.a. finds the outputs) for the first 10 sentences\n",
    "    # TODO we will do the same for batches (maybe size 64)\n",
    "    outputs = model(\n",
    "        input_ids=data['input_ids'],\n",
    "        labels=data['labels'])\n",
    "\n",
    "    # get the features in the last layer\n",
    "    # TODO is it better to get the features in the second last layer [-2] than the last layer [-1]\n",
    "    last_layer = outputs.hidden_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the representation of a sentence, combine all the words embeddings (by averaging them) to become a single sentence embedding\n",
    "# in other words, we want to get rid of the middle dimension (the <SENTENCE_LENGTH> dimension), which is at index 1 of the shape\n",
    "# the shape is (batch_size, sentence_length, num_features_in_hidden_state)\n",
    "sentence_embedding = last_layer.mean(1)\n",
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a vector that represents each sentence, we need to write it to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import csv\n",
    "\n",
    "SENTENCE_EMBEDDING_FILE = 'sentence_embeddings.csv'\n",
    "\n",
    "with open(SENTENCE_EMBEDDING_FILE, 'a', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for sentence, id in zip(sentence_embedding, data['id']):\n",
    "        writer.writerow([id.tolist()] + sentence.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best to zip this csv as it will have a large size and might be difficult to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': tensor(1408),\n",
       " 'input_ids': tensor([  101,  5253,  5922,  1998,  2014,  6658,  1010,  2520,  8233,  1010,\n",
       "          2024,  2006,  1037,  8795,  2000,  8980,  1996,  2093,  8810,  1997,\n",
       "          1037,  8813,  4949,  1012,  6854,  1010,  1996,  2345,  4664,  2003,\n",
       "          2218,  2011,  2014, 25303,  4470,  1010,  4830, 27767,  1012,  2014,\n",
       "          3626,  2003, 18386,  1997,  2014,  4105,  7590,  1010,  2061,  2016,\n",
       "          2442,  3143,  2014,  8795,  2077,  2027, 19306,  2114,  2014,  1012,\n",
       "          2023,  2003,  2081,  2664,  2062,  3697,  2011,  1996,  4073,  1997,\n",
       "          1996,  2329,  4410,  2000,  2203,  2014, 11304, 11217,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "embed_df = pd.read_csv('sentence_embeddings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "894b74110dc0cb78bc9a7fb989438ed7fabe7ad8d7a782ec4a035d78b61e245b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
